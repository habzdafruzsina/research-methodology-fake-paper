\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{draftwatermark}
\usepackage{inputenc}
\usepackage{biblatex}

\SetWatermarkText{Fictional}
\SetWatermarkFontSize{4cm}
\SetWatermarkScale{4.4}

\addbibresource{refs.bib}

\title{Automatic improvement of the location of web elements in automated test cases with the help of an FTPK tool}
\author{test-automation group}
\date{April 2023}

\begin{document}

\maketitle

\section{Introduction}

Software testing is an essential phase in the software development life cycle (SDLC). It helps to ensure that the software product meets the specified requirements and functions as expected. Test automation has gained considerable attention due to its potential to reduce the testing time and improve the quality of the software product. However, maintaining test scripts can be challenging, especially when the program changes\cite{gui_testing, gui_test_costs}. Existing tools can have costly runtime, and they can be inaccurate, and may not have the ability to handle the problem of test oracle\cite{test_oracle_ai}. Therefore, there is a need for a new approach to test automation that can address these issues.

Manual testing has been the traditional method of testing software applications. However, with the increasing complexity of software applications, manual testing has become time-consuming, expensive, and prone to human error\cite{gui_test_costs}. Automation testing has emerged as a viable alternative to manual testing, providing developers with the ability to execute tests automatically, quickly, and with minimal human intervention.

Automation testing is crucial in ensuring that software applications meet the desired quality standards. Automation testing provides several advantages over manual testing, including faster test execution, increased test coverage, and better accuracy. However, automation testing also has its disadvantages, including the need for technical expertise, higher initial costs, and the risk of false positives and false negatives.

There are several types of automation testing, including functional testing, regression testing, load testing, and performance testing. Each type of automation testing has its specific use case, and developers can choose the appropriate type of automation testing based on the application's requirements.

DevOps is a software development methodology that emphasizes collaboration and integration between developers and operations teams. Automation testing plays a critical role in the DevOps methodology, as it enables developers to integrate testing into their development pipeline, facilitating the continuous delivery of software applications.

In conclusion, automation testing has become an essential aspect of modern software development. Its advantages in terms of speed, accuracy, and test coverage make it a compelling alternative to manual testing. The various types of automation testing and its connection to DevOps further highlight the importance of automation testing in software development. This research paper aims to provide an in-depth analysis of automation testing and its significance in the software development life cycle.

In this research paper, we propose a new approach to test automation using web element localization to make more robust test cases for GUI testing. We mainly focused on web elements, but this approach can be used also on other GUI structures, such as Android apps, or Windows desktop applications. The main idea is to relocalize web elements by their properties and tell if the change in the code was the desired, correct behaviour or not. 

Our research aims to address this challenge by introducing a new web element localization method that is capable of finding major differences between code states and providing solutions to adjust automated test cases accordingly.

The proposed web element localization method is designed to identify web elements based on their unique attributes, such as ID, class, name, or XPath, across different code states. By comparing these attributes, the method is able to detect major changes in the web page's structure and provide solutions to adjust automated test cases. These solutions may include modifying test scripts or updating web element locators to ensure that the automated test cases continue to function as expected.

This approach can help to stop rerunning our webelement relocalization algorithm, which produces an optimized solution. It can improve the accuracy and reliability of automated test cases by ensuring that they continue to function as expected.

By providing solutions to adjust automated test cases, our proposed method can help organizations to achieve faster software delivery cycles while maintaining high levels of quality and reliability. We named our tool FTPK after the researchers.

The following questions will guide our research:

\begin{itemize}
\item How can we relocalize webelements by their properties?
\item How many times should the approach search?
\item Can this approach help to reduce the cost of test automation?
\item Can this approach improve the accuracy of test results?
\item Can this approach solve the test oracle problem?
\item Is this approach better, than Similo, or Dalia Alamleh's approach alone?
\end{itemize}

In the next sections of this research paper, we will describe our tool in detail, present the results of our experiments, and discuss the implications of our findings.

\maketitle

\section{Related work}

Related work in this area includes WATER\cite{water}, WATERFALL\cite{waterfall}, COLOR\cite{color}, ROBULA\cite{robula}, ATA-QW\cite{ata}, SIDEREAL\cite{sidereal}, Leotta's Multi-Locator (LML)\cite{lml}, Similo\cite{similo}, Fuzzy-DEMATEL, Neuro-Fuzzy Logic (NFL), Dalia Alamleh's approach (DAA)\cite{fuzzy_ai_in_web_testing} and AI in test automation\cite{ai_in_test_auto}. These approaches have various strengths and weaknesses, and they focus on different aspects of test automation.

The WATER approach by Choudhary\cite{water}. is a tool-based approach that uses differential testing to repair test scripts. WATERFALL\cite{waterfall}, an improvement of WATER\cite{water}, takes into account intermediate minor versions to improve its effectiveness. COLOR, a recent tool proposed by Kirinuki\cite{color}, considers various properties to propose a repair and outperforms WATER\cite{water} in complex changes. Erratum by Brisset\cite{erratum} utilizes a DOM tree matching algorithm to repair broken locators with a 67\% better accuracy than WATER\cite{water}. These approaches offer new solutions to the challenges of maintaining and repairing test scripts in software development, enhancing the reliability and efficiency of test automation.

The literature has proposed several novel approaches to generate robust locators for web testing\cite{robust_locators, robula+}. Montoto\cite{montoto} developed an algorithm that generates XPath expressions iteratively, starting from a simple expression and extending it until the target element is identified. Leotta proposed two algorithms, ROBULA\cite{robula} and ROBULA+\cite{robula+}, with the latter being considered the state-of-the-art algorithm. It generates locators iteratively, starting from a generic XPath locator and refining it using a set of transformations according to specialisation steps, prioritisation, and blacklisting techniques. Another approach is to consider not only the attributes of the target web element but also its neighboring web elements, as proposed by Yandrapally\cite{yandrapally}. Their suggested enhancement, called ATA-QV\cite{ata}, aims to improve the robustness of locating web elements compared to using absolute XPath's by relying more on labels (i.e., visual landmarks) and less on page structure. ATA\cite{ata}, a commercial tool developed at IBM, associates web elements with neighboring labels to pursue the robustness of locators.

Similo approach by Michel Nass\cite{similo} combines several technical solutions to improve locator robustness by collecting locator parameters from all visible web elements, using neighboring web element information, and allowing all locator parameters to be compared, weighted, and tallied into a combined similarity score for each web element. It enables using a threshold value to filter how similar candidate web elements have to be considered a match, which is not provided by other approaches.

Recently, AI-based locator generation algorithms have been proposed by commercial tools and academic papers\cite{ai_in_testing}, such as SIDEREAL\cite{sidereal} and the algorithm proposed by Nguyen\cite{nguyen}.
In the research of "Testing web-based applications: the state of the art and future trends"\cite{state_of_art}, the authors have presented a novel approach of providing a test oracle for software using deep learning and fuzzy inference systems (FIS). The proposed work applied only for the software that has numeric output. They used the FIS as a first layer to map inputs into a fuzzy space. Mainly, this layer is used to train the Deep learning network layer. The second layer is the deep learning network, which is designed to process data provided by the FIS and try to find a pattern. Based on that, the output of the Deep learning network is the test oracle. Authors have tested their approach on different software and approved its validity.

Several researchers have explored the use of fuzzy logic and artificial intelligence in software testing to improve the accuracy and efficiency of testing processes. One such approach is the DAA fuzzy approach, which utilizes a FIS to determine the correctness of two states of web application code. In their study, Dalia Alamleh proposed a DAA fuzzy approach that uses a fuzzy logic-based comparison algorithm to detect differences between two versions of web application code. 

Fuzzy logic is a mathematical concept that allows for reasoning and decision-making in situations where traditional Boolean logic fails to provide a clear answer. Unlike Boolean logic, which assigns binary values of true or false to statements, fuzzy logic allows for the assignment of partial truth values, ranging from completely true to completely false. The key advantage of fuzzy logic is its ability to model complex systems with vague or incomplete information, which can lead to more accurate and nuanced decision-making.

The proposed approach uses a FIS to assign a degree of correctness to the comparison results, allowing for a more accurate determination of the differences between the two code states.

A FIS is a computational model that uses fuzzy logic to simulate human reasoning and decision-making processes. It consists of a set of fuzzy rules that relate input variables to output variables, a fuzzification module that converts crisp inputs into fuzzy values, and an inference engine that applies the fuzzy rules to derive the output variables. FISs are commonly used in control systems, data analysis and pattern recognition. One advantage of FISs is their ability to handle imprecise and uncertain data, making them particularly useful in situations where traditional mathematical models fail to provide accurate results. Overall, FISs are a powerful tool that can be used to solve our detection problem. The FIS is used to analyze the test results and determine the degree of correctness of the web application changes. 

The DAA Fuzzy approach\cite{fuzzy_ai_in_web_testing} is able to effectively detect faults in web codes and provide accurate and reliable results....

Overall, the use of fuzzy logic and artificial intelligence in software testing has shown promising results in improving the accuracy and efficiency of testing processes. The DAA fuzzy approach, specifically, has shown potential in accurately determining the correctness of two states of web application code and can contribute to the overall improvement of software testing processes.

Our solution is based on the Similo\cite{similo} and DAA\cite{fuzzy_ai_in_web_testing}. We tried to combine them in a way to use the strength of both, and eliminate the weeknesses. Similo\cite{similo} utilizes the triangulation of multiple locator information to identify correct GUI elements (web elements in this study). The approach is shown to be more effective at finding elements than the baseline solution and efficient enough for practical use. However, defining a suitable value for the threshold is non-trivial. If the threshold is set too high, that might eliminate valid matches, and if it is set too low, incorrect matches may be chosen due to the aforementioned synchronization challenge. So we try to esteem this value by using the DAA\cite{fuzzy_ai_in_web_testing}, which is able to tell if the code was correctly changed or not. DAA\cite{fuzzy_ai_in_web_testing} proposed a test automation which utilizes an intelligent decision-making algorithm known as fuzzy logic by using Fuzzy set theory which classifies the inputs to predict the output. This approach can predict any possible results for a combination of two inputs. According to Dalia Alamleh's results\cite{fuzzy_ai_in_web_testing}; the FIS seems to be a great artificial intelligent approach that can provide a test oracle for functional testing applied on web applications.

\maketitle

\section{Methodology}

To repair failed test scripts, our methodology involves several steps. First, we run the tests and identify the ones that failed. We then classify the failed tests based on the not found web elements. Next, we use DAA fuzzy logic\cite{fuzzy_ai_in_web_testing} to distinguish between correct and incorrect code changes that may have caused the failures.

If (according to the DAA's results) the test failed due to an incorrect code change, we put it aside and mark it as FAILED. On the other hand, if the test fails due to a correct code change, we run the Similo\cite{similo} algorithm on one test from each group (a representative of the group). If the most similar web element (according to the Similo\cite{similo} ranking) doesn't corrects the test script, then we try again with the second most similar, third, and so on, until we find the correct one, or we reach the given limit for tying. 

After rerunning the failed tests with the optimized approach, we collect the results and show them to a human expert. The expert can analyze the results and determine if the repairs are accurate and reliable. If necessary, the expert can make further modifications to the test scripts.

By using this methodology, we can improve the accuracy and efficiency of test automation, while also reducing the cost and effort required for maintenance. The use of fuzzy logic and algorithms can help to minimize the impact of code changes on the test scripts, ensuring that they remain reliable and effective in detecting software bugs and errors.



\maketitle

\section{Result}

Our new web element localization method allows automated tests to function effectively even if the structure of the tested website changes. This results in significant performance and robustness gains in the testing process. Our method is capable of identifying individual web elements based on their unique properties, such as ID, class, name, or XPath, and by comparing these properties between different states, it can determine what changes have occurred on the webpage.

When our proposed method identifies changes, it makes suggestions for adapting the automated tests. These suggestions may include modifying the testing scripts or updating the web element locators. The results are very promising because this method greatly improves the accuracy and reliability of automated tests and allows the testing process to remain stable even as the application's structure changes.

This approach significantly improves the efficiency of the testing process and enables testers to write tests quickly and efficiently, even if the tested application is very dynamic due to changes. The result will be faster delivery of applications, fewer errors, and improved quality, which is beneficial for developers and users in every way.

\maketitle

\section{Discussion}


\maketitle

\section{Conclusions and future work}


\maketitle

\section{Acknowledgements}

We would like to express our deepest gratitude towards the Eötvös Loránd University for providing us with the resources and facilities needed to conduct this research. Without the support of the university, this study would not have been possible.

We also extend our sincere thanks to the two anonymous reviewers who provided valuable feedback and constructive criticism that helped improve the quality of this paper. Their insights and suggestions have greatly contributed to the final version of this manuscript.

Finally, we would like to thank all the participants who generously gave their time and energy to take part in this study. Their cooperation and willingness to share their experiences have been invaluable to our research.

\maketitle

\section{References}

\printbibliography

\end{document}
